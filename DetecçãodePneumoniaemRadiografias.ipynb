{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435a7c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545bf538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "# otimizador Adam\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# O padrão é 0.001. Vamos tentar um valor menor.\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "\n",
    "# --- Parâmetros ---\n",
    "IMAGE_WIDTH = 150\n",
    "IMAGE_HEIGHT = 150\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 25\n",
    "\n",
    "# --- Diretórios do Dataset ---\n",
    "# IMPORTANT: Update the path below to where your 'chest_xray' folder is located in your Google Drive.\n",
    "# After mounting your Google Drive, it will typically be under /content/drive/MyDrive/\n",
    "# base_dir_drive = '/content/chest_xray/' # <--- **UPDATE THIS PATH**\n",
    "base_dir_drive = '/kaggle/input/chest-xray-pneumonia/chest_xray/' # <--- **UPDATE THIS PATH**\n",
    "\n",
    "train_dir = os.path.join(base_dir_drive, 'train')\n",
    "validation_dir = os.path.join(base_dir_drive, 'val')\n",
    "test_dir = os.path.join(base_dir_drive, 'test')\n",
    "\n",
    "\n",
    "# --- Check if directories exist ---\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Checking for dataset in: {base_dir_drive}\")\n",
    "\n",
    "if not os.path.exists(train_dir):\n",
    "    print(f\"Error: Training directory not found at {train_dir}\")\n",
    "    print(\"Please make sure the 'chest_xray' folder is in the correct location in your Google Drive and the 'base_dir_drive' path above is correct.\")\n",
    "if not os.path.exists(validation_dir):\n",
    "    print(f\"Error: Validation directory not found at {validation_dir}\")\n",
    "if not os.path.exists(test_dir):\n",
    "    print(f\"Error: Test directory not found at {test_dir}\")\n",
    "\n",
    "\n",
    "# --- Geradores de Dados com Data Augmentation ---\n",
    "# Ensure directories exist before creating generators\n",
    "if os.path.exists(train_dir) and os.path.exists(validation_dir) and os.path.exists(test_dir):\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    # O gerador de validação e teste não deve ter data augmentation, apenas o rescale\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # --- Construção do Modelo ---\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3)),\n",
    "        MaxPooling2D(2, 2),\n",
    "\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "\n",
    "        Flatten(),\n",
    "        Dropout(0.5), # Dropout para regularização\n",
    "\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(1, activation='sigmoid') # Sigmoid para classificação binária\n",
    "    ])\n",
    "\n",
    "    # --- Compilação do Modelo ---\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # --- Treinamento do Modelo ---\n",
    "    # Only attempt to train if generators were created successfully\n",
    "    if train_generator.samples > 0 and validation_generator.samples > 0:\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=validation_generator.samples // BATCH_SIZE\n",
    "        )\n",
    "\n",
    "        # --- Avaliação do Modelo ---\n",
    "        # Only attempt to evaluate if test generator has samples\n",
    "        if test_generator.samples > 0:\n",
    "            test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // BATCH_SIZE)\n",
    "            print(f'Acurácia no conjunto de teste: {test_acc:.2f}')\n",
    "        else:\n",
    "            print(\"Skipping model evaluation: No images found in the test directory.\")\n",
    "    else:\n",
    "        print(\"Skipping model training and evaluation: No images found in training or validation directories.\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping data generation, model training, and evaluation due to missing directories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bc37bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o modelo inteiro em um único arquivo .h5\n",
    "model.save('detector_pneumonia.h5')\n",
    "\n",
    "print(\"Modelo salvo com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
